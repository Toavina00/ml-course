{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa711c8c-2e86-41e1-8430-b9036bfdc8f9",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a15a99-6aa9-455c-a6c1-b97a3a1cee16",
   "metadata": {},
   "source": [
    "> Ce notebook utilise les templates fournis durant les exercices d'application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd93385d-3dbf-40de-ad55-abda95d27548",
   "metadata": {
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff94e78d54f43a893b923566f0b16510",
     "grade": false,
     "grade_id": "cell-678763ad276cc09f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "from sklearn.linear_model import Ridge \n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "data = datasets.load_diabetes()\n",
    "X_train, y_train = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fca674b-ad0e-45ad-8f7c-819055f7cb5f",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "18180df278e73e6f76e771368ec05383",
     "grade": false,
     "grade_id": "cell-b05eee3d44b96fa8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "def fit_lu(X, y):\n",
    "    \n",
    "    \"\"\" Find optimal w using LU decomposition \"\"\"\n",
    "    \n",
    "    L, U = sp.linalg.lu(X.T @ X, permute_l=True)\n",
    "    b = np.linalg.solve(L, X.T.dot(y))\n",
    "    return np.linalg.solve(U, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08c4072-5563-4626-8e7a-464c177b12cc",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a8508caf7357c557a41778fb85eeed7",
     "grade": false,
     "grade_id": "cell-f47228b1d23c9c3d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction error:  3.410551082478826e-14\n"
     ]
    }
   ],
   "source": [
    "w = fit_lu(X_train, y_train)\n",
    "\n",
    "sk_model = LR(fit_intercept=False)\n",
    "sk_model.fit(X_train, y_train)\n",
    "\n",
    "error = rel_error(sk_model.coef_, w)\n",
    "print(\"prediction error: \", error)\n",
    "assert error <= 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e23f4d6-39eb-4f10-9743-b7e2bc5ff477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_jacobi(X, y, eps=1e-3):\n",
    "    \n",
    "    \"\"\" Find optimal w using Jacobi \"\"\"\n",
    "    \"\"\" return w in the method convergent, None otherwise \"\"\"\n",
    "    \n",
    "    N, d = X.shape\n",
    "    \n",
    "    A, b = X.T @ X, X.T @ y\n",
    "    m = A.diagonal()\n",
    "    M = np.diag(m)\n",
    "    N = M - A\n",
    "    \n",
    "    if np.linalg.det(M) == 0:\n",
    "        return None\n",
    "    \n",
    "    Mi = np.diag(1/m)\n",
    "    \n",
    "\n",
    "    w = np.zeros(d)\n",
    "    wn = 0.0\n",
    "    \n",
    "    Z = Mi @ N\n",
    "    _, S, _ = np.linalg.svd(Z)\n",
    "    \n",
    "    if S[0] >= 1:\n",
    "        return None\n",
    "    \n",
    "    while True:\n",
    "        wn = Z @ w + Mi @ b\n",
    "        if np.linalg.norm(wn - w) < eps:\n",
    "            break\n",
    "        w = wn\n",
    "    \n",
    "    return wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ffe0b7f-3cc8-4ab9-9069-a6305fdad8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gauss_siedel(X, y, eps=1e-3):\n",
    "    \n",
    "    \"\"\" Find optimal w using Gauss Siedel \"\"\"\n",
    "    \"\"\" return w in the method convergent, None otherwise \"\"\"\n",
    "    \n",
    "    N, d = X.shape\n",
    "    \n",
    "    A, b = X.T @ X, X.T @ y\n",
    "    D = np.diag(A.diagonal())\n",
    "    E, F = D - A.copy(), D - A.copy()\n",
    "    for i in range(A.shape[1]):\n",
    "        F[i:, :i] = 0\n",
    "        E[:i, i:] = 0\n",
    "   \n",
    "    M = D - E\n",
    "    N = F\n",
    "    \n",
    "    if np.linalg.det(M) == 0:\n",
    "        return None\n",
    "    \n",
    "    Mi = np.linalg.inv(M)\n",
    "\n",
    "    w = np.zeros(d)\n",
    "    wn = 0.0\n",
    "\n",
    "    Z = Mi @ N\n",
    "    _, S, _ = np.linalg.svd(Z)\n",
    "    \n",
    "    if S[0] >= 1:\n",
    "        return None\n",
    "    \n",
    "    while True:\n",
    "        wn = Z @ w + Mi @ b\n",
    "        if np.linalg.norm(wn - w) < eps:\n",
    "            break\n",
    "        w = wn\n",
    "    \n",
    "    return wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7521f4f1-929a-4286-ad02-e48128365a77",
   "metadata": {},
   "source": [
    "## Combine everything in a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93eb2da7-4ddf-4a4f-ac0b-9551846ddbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    def __init__(self, fit_intercept=True, method=\"lu\"):\n",
    "        self.w = 0\n",
    "        self.fit_intercept = fit_intercept # bias\n",
    "        self.method = method\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        X =  np.hstack( (np.ones((X.shape[0],1)), X) ) if self.fit_intercept else X.copy()\n",
    "        if self.method == \"lu\":\n",
    "            self.w = fit_lu(X, y)\n",
    "        elif self.method == \"jacobi\":\n",
    "            self.w = fit_jacobi(X, y)\n",
    "        elif self.method == \"gauss_siedel\":\n",
    "            self.w = fit_gauss_siedel(X, y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X = np.hstack( (np.ones((X.shape[0],1)), X) ) if self.fit_intercept else X.copy()\n",
    "        return X.dot(self.w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
