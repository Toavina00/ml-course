{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f33bcf3",
   "metadata": {},
   "source": [
    "# MISA\n",
    "Alohan'ny mamerina dia avereno atao Run ny notebook iray manontolo. Ny fanaovana azy dia red√©marrena mihitsy ny kernel aloha (jereo menubar, safidio **Kernel$\\rightarrow$Restart Kernel and Run All Cells**).\n",
    "\n",
    "Izay misy hoe `YOUR CODE HERE` na `YOUR ANSWER HERE` ihany no fenoina. Afaka manampy cells vaovao raha ilaina. Aza adino ny mameno references eo ambany raha ilaina."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2f4e2",
   "metadata": {},
   "source": [
    "## References\n",
    "Eto ilay references rehetra no apetraka"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11c7e99",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46325dc4-11c5-4f0c-b501-dac902481267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "data = load_diabetes()\n",
    "X_train, y_train = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3544cecd-9ab5-4e41-814b-2b6b3f6de92c",
   "metadata": {},
   "source": [
    "# Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d31a475e-a09e-4668-b0fe-78d4ebd339c7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5b0c4715733278a49f39874fc066611",
     "grade": false,
     "grade_id": "cell-210d2ae0b70955f7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel(x1, x2, sigma=1.0):\n",
    "    return np.exp(- np.sum((x1 - x2)**2) / sigma)\n",
    "\n",
    "class KernelRidgeRegression():\n",
    "    def __init__(self, kernel, lambd=1.0):\n",
    "        self.lambd = lambd # regularization coefficient\n",
    "        self.alpha = None # dual variable\n",
    "        self.kernel = kernel # kernel function\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        N, d = X.shape\n",
    "        \n",
    "        K = np.zeros((N,N))\n",
    "        \n",
    "        for i in range(N):\n",
    "            for j in range(N):\n",
    "                K[i, j] = self.kernel(X[i], X[j])\n",
    "        \n",
    "        A = K + self.lambd * np.eye(N)\n",
    "        Q, R = np.linalg.qr(A)\n",
    "        \n",
    "        self.alpha = np.linalg.solve(R, Q.T @ y)\n",
    "        self.w = X.T @ self.alpha\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return X @ self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b1c7054-0d6f-43ab-94fa-6d2607a0d42f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9faf80a32ceda54b9dc748eb4045fcec",
     "grade": true,
     "grade_id": "cell-7d655e9354dd8a5a",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:  5.692326333690524e-13\n",
      "prediction error:  0.0\n"
     ]
    }
   ],
   "source": [
    "kr = KernelRidgeRegression(kernel=gaussian_kernel)\n",
    "kr.fit(X_train,y_train)\n",
    "y_pred = kr.predict(X_train)\n",
    "\n",
    "sklearn_kr = KernelRidge(kernel=gaussian_kernel)\n",
    "sklearn_kr.fit(X_train,y_train)\n",
    "sklearn_y_pred = kr.predict(X_train)\n",
    "\n",
    "error = rel_error(kr.alpha, sklearn_kr.dual_coef_)\n",
    "print(\"error: \", error)\n",
    "assert error <= 1e-11\n",
    "\n",
    "error_pred = rel_error(y_pred, sklearn_y_pred)\n",
    "print(\"prediction error: \", error_pred)\n",
    "assert error_pred <= 1e-11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13635bf3-2672-4cd8-a027-ee36ae8ff325",
   "metadata": {},
   "source": [
    "# Non-negative Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "043d9306-82f9-4fb7-b0f0-3c3d140edc30",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "94da84f06c7b1f904e1a0c6bef2e101f",
     "grade": false,
     "grade_id": "cell-37e7efb4bf96fe1a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NonNegativeLinearRegression:\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.w = None\n",
    "        self.fit_intercept = fit_intercept\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X =  np.hstack( (np.ones((X.shape[0],1)), X) ) if self.fit_intercept else X.copy()\n",
    "        \n",
    "        N, d = X.shape\n",
    "        \n",
    "        w = cp.Variable(d, nonneg=True)\n",
    "        \n",
    "        objective = cp.Minimize(cp.sum_squares(X@w - y))\n",
    "       \n",
    "        problem = cp.Problem(objective)\n",
    "        problem.solve(verbose=True)\n",
    "    \n",
    "        self.w = w.value\n",
    "\n",
    "    def predict(self, X):\n",
    "        X =  np.hstack( (np.ones((X.shape[0],1)), X) ) if self.fit_intercept else X.copy()\n",
    "        return X @ self.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64e72e68-1588-45e1-a2d3-6f052f5ebc9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.3                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 26 09:57:33 AM: Your problem has 11 variables, 0 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 26 09:57:33 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 26 09:57:33 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 26 09:57:33 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Oct 26 09:57:33 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 26 09:57:33 AM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Oct 26 09:57:33 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Oct 26 09:57:33 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 26 09:57:33 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 26 09:57:33 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 26 09:57:33 AM: Applying reduction OSQP\n",
      "(CVXPY) Oct 26 09:57:33 AM: Finished problem compilation (took 1.030e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 26 09:57:33 AM: Invoking solver OSQP  to obtain a solution.\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v0.6.3  -  Operator Splitting QP Solver\n",
      "              (c) Bartolomeo Stellato,  Goran Banjac\n",
      "        University of Oxford  -  Stanford University 2021\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 453, constraints m = 453\n",
      "          nnz(P) + nnz(A) = 5757\n",
      "settings: linear system solver = qdldl,\n",
      "          eps_abs = 1.0e-05, eps_rel = 1.0e-05,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 10000\n",
      "          check_termination: on (interval 25),\n",
      "          scaling: on, scaled_termination: off\n",
      "          warm start: on, polish: on, time_limit: off\n",
      "\n",
      "iter   objective    pri res    dua res    rho        time\n",
      "   1   0.0000e+00   3.46e+02   6.72e+06   1.00e-01   7.65e-04s\n",
      "  75   1.3588e+06   1.42e-07   5.91e-08   1.37e+00   2.51e-03s\n",
      "plsh   1.3588e+06   5.68e-14   7.11e-13   --------   2.93e-03s\n",
      "\n",
      "status:               solved\n",
      "solution polish:      successful\n",
      "number of iterations: 75\n",
      "optimal objective:    1358786.9764\n",
      "run time:             2.93e-03s\n",
      "optimal rho estimate: 1.25e+00\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 26 09:57:33 AM: Problem status: optimal\n",
      "(CVXPY) Oct 26 09:57:33 AM: Optimal value: 1.359e+06\n",
      "(CVXPY) Oct 26 09:57:33 AM: Compilation took 1.030e-02 seconds\n",
      "(CVXPY) Oct 26 09:57:33 AM: Solver (including time spent in interface) took 4.370e-03 seconds\n",
      "MSE scikit-learn: 2859.69634758675\n",
      "MSE gradient descent model : 27058.848789960928\n",
      "Difference 24199.15244237418\n"
     ]
    }
   ],
   "source": [
    "nnlr = NonNegativeLinearRegression(fit_intercept=True)\n",
    "nnlr.fit(X_train,y_train)\n",
    "y_pred = kr.predict(X_train)\n",
    "mse = mean_squared_error(y_pred, y_train)\n",
    "\n",
    "sk_model = LinearRegression(fit_intercept=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "sk_mse = mean_squared_error(sk_pred, y_train)\n",
    "\n",
    "print(\"MSE scikit-learn:\", sk_mse)\n",
    "print(\"MSE gradient descent model :\", mse)\n",
    "print(f\"Difference {abs(sk_mse - mse)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7a949471-582b-493c-bfab-836da2646535",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8917c314e70ebfe96ae668660973e17f",
     "grade": true,
     "grade_id": "cell-b1a1983846be3759",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.5.3                                    \n",
      "===============================================================================\n",
      "(CVXPY) Oct 26 09:54:26 AM: Your problem has 11 variables, 0 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 26 09:54:26 AM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 26 09:54:26 AM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 26 09:54:26 AM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Oct 26 09:54:26 AM: Your problem is compiled with the CPP canonicalization backend.\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 26 09:54:26 AM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Oct 26 09:54:26 AM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Oct 26 09:54:26 AM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 26 09:54:26 AM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 26 09:54:26 AM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 26 09:54:26 AM: Applying reduction OSQP\n",
      "(CVXPY) Oct 26 09:54:26 AM: Finished problem compilation (took 1.562e-02 seconds).\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 26 09:54:26 AM: Invoking solver OSQP  to obtain a solution.\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v0.6.3  -  Operator Splitting QP Solver\n",
      "              (c) Bartolomeo Stellato,  Goran Banjac\n",
      "        University of Oxford  -  Stanford University 2021\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 453, constraints m = 453\n",
      "          nnz(P) + nnz(A) = 5757\n",
      "settings: linear system solver = qdldl,\n",
      "          eps_abs = 1.0e-05, eps_rel = 1.0e-05,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 10000\n",
      "          check_termination: on (interval 25),\n",
      "          scaling: on, scaled_termination: off\n",
      "          warm start: on, polish: on, time_limit: off\n",
      "\n",
      "iter   objective    pri res    dua res    rho        time\n",
      "   1   0.0000e+00   3.46e+02   6.72e+06   1.00e-01   7.28e-04s\n",
      "  75   1.3588e+06   1.42e-07   5.91e-08   1.37e+00   2.47e-03s\n",
      "plsh   1.3588e+06   5.68e-14   7.11e-13   --------   2.98e-03s\n",
      "\n",
      "status:               solved\n",
      "solution polish:      successful\n",
      "number of iterations: 75\n",
      "optimal objective:    1358786.9764\n",
      "run time:             2.98e-03s\n",
      "optimal rho estimate: 1.25e+00\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "(CVXPY) Oct 26 09:54:26 AM: Problem status: optimal\n",
      "(CVXPY) Oct 26 09:54:26 AM: Optimal value: 1.359e+06\n",
      "(CVXPY) Oct 26 09:54:26 AM: Compilation took 1.562e-02 seconds\n",
      "(CVXPY) Oct 26 09:54:26 AM: Solver (including time spent in interface) took 5.240e-03 seconds\n",
      "MSE scikit-learn: 3074.1786797315144\n",
      "MSE gradient descent model : 27058.848789960928\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE scikit-learn:\u001b[39m\u001b[38;5;124m\"\u001b[39m, sk_mse)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMSE gradient descent model :\u001b[39m\u001b[38;5;124m\"\u001b[39m, mse)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mse \u001b[38;5;241m-\u001b[39m sk_mse \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m200\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nnlr = NonNegativeLinearRegression(fit_intercept=True)\n",
    "nnlr.fit(X_train,y_train)\n",
    "y_pred = kr.predict(X_train)\n",
    "mse = mean_squared_error(y_pred, y_train)\n",
    "\n",
    "sk_model = LinearRegression(fit_intercept=True, positive=True)\n",
    "sk_model.fit(X_train, y_train)\n",
    "sk_pred = sk_model.predict(X_train)\n",
    "sk_mse = mean_squared_error(sk_pred, y_train)\n",
    "\n",
    "print(\"MSE scikit-learn:\", sk_mse)\n",
    "print(\"MSE gradient descent model :\", mse)\n",
    "assert mse - sk_mse < 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99731914-22db-40bd-868e-82d8016a6ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
